<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Yuntao Du, Shandong University"> 
<meta name="description" content="Yuntao Du's home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuntao Du's homepage</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
<style>
  .left-align {
    text-align: left;
  }
</style>
	
</script>
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Yuntao Du </font></h1>  <h1><font face="Ê•∑‰Ωì"> Êùú‰∫ëÊ∂õ </font></h1>
				</div>

				<h3><font face="Arial"> Associate Researcher </font></h3>
				<p><font face="Arial"> 
					Joint SDU-NTU Centre for Artificial Intelligence Research & School of Software <br>
					<a href="https://www.sc.sdu.edu.cn/" target="_blank"> Shandong University</a> <br>
					Jinan, China <br>
					<br>
					Email: <a href="duyuntao@bigai.ai">yuntaodu@sdu.edu.cn</a> <br>
				</font></p>
			</td>
			<td>
				<img src="yuntaodu.jpg" border="0" width="180"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2><font face="Arial"> About </font></h2>
<p class="left-align";>

    Currently, I am  working as an Associate Researcher in the Joint SDU-NTU Centre for Artificial Intelligence Research at Shandong University. 
    Before that, I was a research scientist at the Beijing Institute for General Artificial Intelligence (BIGAI) from 2023~2025. 
    I got a Ph.D degree from  Nanjing University in June 2023. I was a member of
    <a href = "http://iip.nju.edu.cn/index.php/%E9%A6%96%E9%A1%B5" target="_blank" style= "color:blue; text-decoration:none;" >IIP Group</a>,
    led by a professor
    <a href = "https://cs.nju.edu.cn/58/06/c2639a153606/page.htm" target="_blank" style= "color:blue; text-decoration:none;" >Chongjun Wang</a>. 
    Before that, I received my B.Sc. degree from Northeastern University in June 2018. 
    
    <br> 
    <br> 
    
    I have published more than thirty papers in top conferences and journals, including ICML, NeurIPS, ICLR, CVPR, ECCV, and TMLR. 
    Google Scholar's total citation number is 800, and one paper is selected as "paper digest most influential papers" in CIKM 2021.
    <br> 
    <!-- In September 2018, I was admitted to study for a Ph.D degree at Nanjing University under the supervision of Prof. <a href = "https://cs.nju.edu.cn/58/06/c2639a153606/page.htm" target="_blank" style= "color:blue; text-decoration:none;" >Chongjun Wang</a> without entrance examination, respectively. -->
    <br>
    I am working on multimodal understanding, reasoning, and new knowledge learning. In particular, I'm interested in building models/agents that can generalize well and learn continously in various reasoning and multimodal tasks. Some of my research topic could be found below: 
    <ul>
        <li> <b>Large language model</b>: RAG, Knowledge and reasoning
	      <li> <b>Large multimodal model</b>:  Efficient training and inference,   knowledge editing, model evaluation
        <li> <b>LLM Agent</b>:    Multi-agent system; Agent Applications
        <li> <b>Transfer Learning & Weakly supervised learning </b>:   domain adaptation, test-time adaptation, semi-supervised learning, noisy-label learning 
    </ul>
    
    <p style="color: red;"> <strong> I am looking for self-motivated students. If interested, you are welcome to contact me.
        </strong></p>
      
    <p style="color: red;"> <strong> I am open to collaborating with the field of academia and industry. If interested, you are welcome to contact me.
        </strong></p>

</font></p>

	
<!--<font color="red">Currently, I am working on domain generalization for semantic segmentation and object detection. I am looking for undergraduate or master's students to engage in ongoing research papers. Don't hesitate to email me if you are interested.</font> <br><br>-->
	
<h2><font face="Arial"> News </h2>
<font size = "3"></font>
    <ul>
	  <li> 2025.09 One paper got accepted by <b>NeurIPS 2025 as Spotlight</b></li>
	  <li> 2025.09 I will serve as <b>Area Chair in ICLR 2025</b> </li> 
	  <li> 2025.08 One paper got accepted by <b>EMNLP 2025 Findings</b></li>
      <li> 2025.05 One paper got accepted by <b>ICML 2025</b></li>
      <li> 2025.03 One paper got accepted by <b>Neural Networks</b></li>
      <li> <p style="color: red;">2025.02  <strong> I have joined Shandong University as an Associate Researcher in C-FAIR.  </strong></p>
      </li>
      <li> 2025.01 One paper got accepted by <b>ICLR 2025</b></li>
      <li> 2024.12 One paper got accepted by <b>AAAI 2025</b></li>
      <li> 2024.11 One paper got accepted by <b>Neurocomputing 2024</b></li>
      <li> 2024.09 One paper got accepted by <b>NeurIPS 2024</b></li>
      <li> 2024.08 One paper got accepted by <b>Neural Network</b></li>
      <li> 2024.07 One paper got accepted by <b>ECCV 2024</b></li>
      <!-- <li> 2024.03 One paper got accepted by <b>ICLR 2024 workshop</b></li> -->
      <li> 2024.03 One paper got accepted by <b>CVPR 2024</b></li>
      <!-- <li> 2024.02 Our survey on parameter-efficient fine-tuning for vision is on arXiv. Here is the <a href="https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning" target="_blank" style= "color:blue; text-decoration:none;">github link</a> </li> -->
      <li> 2023.10 One paper got accepted by <strong>Machine Learning Journal</strong>
      <li> 2023.03 One paper got accepted by <strong>Transactions on Machine Learning Research (TMLR) </strong>
      <!-- <li> 2023.01 One paper got accepted by <strong>SDM 2023 </strong> -->
<!--         <li> 2022.12 One paper got accepted by <strong>AAAI 2023</strong> -->
<!--         <li> 2022.06 One paper got accepted by <strong>ECML-PKDD 2022</strong>
        <li> 2021.12 One paper got accepted by <strong>AAAI 2022</strong> -->
        <!-- <li> 2021.09 I have been awarded a student travel grant of CIKM 2021</li> -->
        <!-- <li> 2021.09 I have been selected as a PC member of AAAI 2022</li> -->
        <!-- <li> 2021.08 Two papers got accepted by <strong> CIKM 2021 </strong></li>
        <li> 2021.05 One paper got accepted by <strong> ICMR 2021 </strong></li>
        <li> 2021.03 One paper got accepted by <strong> IDA journal 2021 </strong></li>
        <li> 2021.01 Four papers got accepted by <strong> DASFAA 2021 </strong></li> -->
      <!--   <li> 2020.06 One paper got accepted by <strong> ECML-PKDD 2020 </strong></li> -->
      </ul>



<h2><font face="Arial"> Preprint </font></h2>
<font size = "3">
<ul>
   <li> 
	<p>
	<strong> GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging</strong>  
          <a href="https://arxiv.org/abs/2508.18993" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	   </p>
	  Ziyi Ni, Huacan Wang, Shuo Zhang, Shuo Lu, Ziyang He, Wang You, Zhenheng Tang, <b>Yuntao Du</b>, Bill Sun, Hongzhang Liu, Sen Hu, Ronghao Chen, Bo Li, Xin Li, Chen Hu, Binxing Jiao, Daxin Jiang, Pin Lyu
   </li>	
	
	<li> 
	<p>
	<strong> MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media</strong>  
          <a href="https://arxiv.org/pdf/2508.05557" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	   </p>
	  Rui Lu, Jinhe Bi, Yunpu Ma, Feng Xiao, <b>Yuntao Du</b>üìß, Yijun Tianüìß
   </li>	
   <li> 
	<p>
	<strong> Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models.</strong>  
          <a href="https://mllmkcbench.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	   </p>
	  Yifan Jia*, Kailin Jiang*, Yuyang Liang, Qihan Ren, Yi Xin, Rui Yang, Fenze Feng, Mingcai Chen, Hengyang Lu, Haozhe Wang, Xiaoye Qu, Dongrui Liu, Lizhen Cui, <b>Yuntao Du</b>üìß
   </li>	
    <li> 
	   <p>
		   <strong> When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways.</strong>  
       <a href="https://arxiv.org/abs/2505.24449" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	   </p>
           Kailin Jiang*, <b>Yuntao Du*</b>, Yukai Ding, Yuchen Ren, Ning Jiang, Zhi Gao, Zilong Zheng, Lei Liu, Bin Li, Qing Li.
    </li>
    <li>
    <p>
        <strong>Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey and Benchmark </strong>  
        <a href="https://arxiv.org/abs/2402.02242" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
    </p>
    <p>
        Yi Xin, Jianjiang Yang, Siqi Luo, <b>Yuntao Du</b>, Qi Qin, Kangrui Cen, Yangfan He, Bin Fu, Xiaokang Yang, Guangtao Zhai, Ming-Hsuan Yang, Xiaohong Liu
    </p>
    </li>
</ul>


<h2><font face="Arial"> Selected Publications </font></h2>
<font size = "2"></font>
<p><font face="Arial"><a href="https://scholar.google.com/citations?user=1ogwTXkAAAAJ&hl=zh-CN">[Google Scholar]</a></font></p> 
	
<ul>
  <li> 
	<p>
	<strong> RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving.</strong>  
          <a href="https://arxiv.org/abs/2505.21577" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	</p>
	<p>
	   Huacan Wang, Ziyi Ni, Shuo Zhang, Shuo Lu, Sen Hu, Ziyang He, Chen Hu, Jiaye Lin, Yifu Guo, <b>Yuntao Du</b>üìß, Pin Lyüìß
    </p>
    <p>
      <strong>   <p style="color: red;">NeurIPS 2025 (Spotlight, CCF A)</p>   </strong>
    </p> 
   </li>	
	<li>
    <p>
      <strong>	Learning SQL Like a Human: Structure-Aware Curriculum Learning for Text-to-SQL Generation. </strong> 
      <a href="" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a> 
    <p>
	  Xiaohu Zhu, Qian Li, Lizhen Cui, <b>Yuntao Du</b>
    </p>
    <p>
      <strong>   <p style="color: red;">EMNLP 2025 (Findings, CCF B)</p>   </strong>
    </p>
</li>

  <li>
    <p>
      <strong>	Test-Time Selective Adaptation for Uni-Modal Distribution Shift in Multi-Modal Data. </strong> 
      <a href="https://openreview.net/pdf?id=6EZMWeV5sH" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a> 
    <p>
      MingCai Chen, Baoming Zhang, Zongbo Han, <b>Yuntao Du*</b>, Wenyu Jiang, Yanmeng Wang, Shuai Feng, Bingkun BAO
    </p>
    <p>
      <strong>   <p style="color: red;">ICML 2025 (CCF A, Equal Corresponding Author)</p>   </strong>
    </p>
</li>


  <li>
    <p>
      <strong>	MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge. </strong>
      <a href="https://openreview.net/forum?id=v8qABSeeKO&noteId=iGPriZPvEo" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
      <a href="https://mmke-bench-iclr.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
    <p>
      <b>Yuntao Du</b>, Kailin Jiang, Zhi Gao, Chenrui Shi, Zilong Zheng, Siyuan Qi, Qing Li
    </p>
    <p>
     <strong>  <p style="color: red;">ICLR 2025 (Ê∏ÖÂçéAÁ±ª) </p>  </strong> 
    </p>
</li>

<li>
    <p>
      <strong>Robust Logit Adjustment for Learning with Long-Tailed Noisy Data. </strong> 
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33738" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
    <p>
      MingCai Chen, <b>Yuntao Du</b>, Wenyu Jiang, Baoming Zhang, Shuai Feng, Yi Xin, Chongjun Wang
    </p>
    <p>
      <strong> <p style="color: red;">AAAI  2025 (CCF A)  </p>  </strong>
    </p>
</li>

    <li>
    <p>
      <strong>V-PETL Bench: A Unified Visual Parameter-Efficient Transfer Learning Benchmark. </strong> 
       <a href="https://openreview.net/pdf?id=yS1dUkQFnu" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
       <a href="https://v-petl-bench.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
    <p>
      Yi Xin*, Siqi Luo*, Xuyang Liu*, <b>Yuntao Du*</b>, Haodi Zhou, Xinyu Cheng, Christina Luoluo Lee, Junlong Du, Haozhe Wang, MingCai Chen, Ting Liu, Guimin Hu, Zhongwei Wan, Rongchao Zhang, Aoxue Li, Mingyang Yi, Xiaohong Liu
    </p>
    <p>
      <strong>  <p style="color: red;">NeurIPS 2024 (CCF A, Equal first author) </p> </strong>  
    </p>

</li>
    <li>
        <p>
          <strong>VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding. </strong> 
          <a href="https://arxiv.org/abs/2403.11481" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
          <a href="https://videoagent.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
          <a href="https://mp.weixin.qq.com/s/2gG9AUcTc_yutN8zZUGQKQ" target="_blank" style= "color:blue; text-decoration:none;">[Êú∫Âô®‰πãÂøÉ‰∏≠ÊñáÊä•ÈÅì]</a>
        <p>
          Yue Fan, Xiaojian Ma, Rujie Wu, <b>Yuntao Du</b>, Jiaqi Li, Zhi Gao, Qing Li
        </p>
        <p>
          <strong> <p style="color: red;">ECCV 2024 (CCF B) </p> </strong>  
        </p>
    </li>

    <li>
        <p>
          <strong>Multi-source Fully Test-Time Adaptation. </strong> 
          <a href="https://www.sciencedirect.com/science/article/pii/S0893608024005859" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Siqi Luo, Yi Xin, MingCai Chen, Shuai Feng, Mujie Zhang, Chongjun Wang
        </p>
        <p>
          <strong>  <p style="color: red;">Neural Network 2024 (JCR Q1, CCF B) </p> </strong>
        </p>
      </li>
        <li>
          <p>
            <strong> CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update. </strong> 
            <a href="https://arxiv.org/abs/2312.10908" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
            <a href="https://clova-tool.github.io" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
          <p>
            Zhi Gao, <b>Yuntao Du</b>, Xintong Zhang, Xiaojian Ma, Wenjuan Han, Song-Chun Zhu, Qing Li
          </p>
          <p>
            <strong> <p style="color: red;">CVPR 2024 (CCF A)</p>  </strong> 
          </p>
        </li>
      <li>
        <p>
          <strong>Generation, augmentation, and alignment: A pseudo-source domain based method for source-free domain adaptation </strong>
          <a href="https://arxiv.org/abs/2109.04015" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Haiyang Yang, Mingcai Chen, Juan Jiang, Hongtao Luo, and Chongjun Wang.
        </p>
        <p>
          <strong> <p style="color: red;">Machine Learning (MLJ)  2023 (JCR Q1, CCF B)</p>  </strong>
        </p>
      </li>
  
      <li>
        <p>
          <strong>DSCR: Dual View based Symmetric Consistency Regularization for Semi-Supervised Domain Adaptation </strong>
          <a href="https://openreview.net/pdf?id=WVwnccBJLz" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Juan Jiang, Hongtao Luo, Haiyang Yang, Mingcai Chen, and Chongjun Wang.
        </p>
        <p>
          <strong>  <p style="color: red;"> Transactions on Machine Learning Research (TMLR) 2023 </p> </strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong>Two Wrongs Don‚Äôt Make a Right: Combating Confirmation Bias in Learning with Label Noise</strong>
          [<a href="https://arxiv.org/abs/2112.02960" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
        </p>
        <p>
          Mingcai Chen, Hao Cheng, <b>Yuntao Du </b>, Ming Xu, Wenyu Jiang, Chongjun Wang
        </p>
        <p>
          <strong><p style="color: red;"> AAAI 2023 (CCF A) </p> </strong>  
        </p>
      </li>
      <li>
        <p> 
          <strong>InCo: Intermediate Prototype Contrast for Unsupervised Domain Adaptation</strong>
          [<a href="https://link.springer.com/chapter/10.1007/978-3-031-26387-3_39" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
        </p>
        <p>
          <b>Yuntao Du*</b>, Hongtao Luo*, Haiyang Yang, Juan Jiang, and Chongjun Wang
        </p>
        <p  style="color: red;">
           <strong>ECML-PKDD 2022 (CCF B)</strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong> Semi-Supervised Learning with Multi-Head Co-Training</strong>
          [<a href="https://arxiv.org/pdf/2107.04795" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/chenmc1996/Multi-Head-Co-Training" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
        <p>
          Mingcai Chen, <b>Yuntao Du </b>, Yi zhang, Shuwei Qian, and Chongjun Wang
        </p>
        <p style="color: red;">
         <strong> AAAI 2022 (CCF A)</strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong>AdaRNN: Adaptive Learning and Forecasting of Time Series</strong>
          [<a href="https://arxiv.org/abs/2108.04443" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn" target="_blank" style= "color:blue; text-decoration:none;">Code</a>]
          (<b>ÂºïÁî®Ë∂Ö300</b>, Rank 4th in CIKM 2021)  
        </p>
        <p>
          <b>Yuntao Du </b>, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu and Chongjun Wang
        </p>
        <p style="color: red;">
          <strong>CIKM  2021 (CCF B)</strong> 
       </p>
      </li>
  
      <li>
        <p> 
          <strong>Adversarial Separation Network for Cross-Network Node Classification</strong>
          [<a href="https://dl.acm.org/doi/10.1145/3459637.3482228" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/yuntaodu/ASN" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
        <p>
          Xiaowen Zhang *, <b>Yuntao Du *</b>, Rongbiao Xie and Chongjun Wang
        </p>
        <p style="color: red;">
          <strong>CIKM 2021 (CCF B, Euqal first author)</strong> 
        </p>
      </li>

      <!-- <li>
        <p> 
          <strong>Cross-domain error minimization for unsupervised domain adaptation</strong>
        </p>
        <p>
          <b>Yuntao Du</b>, Yinghao Chen *, Fengli Cui *, Xiaowen Zhang, Chongjun Wang. (*, euqal contribution)
        </p>
        <p>
          International Conference on Database Systems for Advanced Applications (<a href="http://dm.iis.sinica.edu.tw/DASFAA2021/" target="_blank" style= "color:blue; text-decoration:none;"><strong>DASFAA</strong></a>) 2021 [<a href="https://arxiv.org/abs/2106.15057" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] [<a href="https://github.com/yuntaodu/CDEM" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
      </li> -->

      <li>
          <p> 
            <strong>Homogeneous Online Transfer Learning with Online Distribution Discrepancy Minimization</strong>
            [<a href="https://arxiv.org/pdf/1912.13226.pdf" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
            [<a href="https://github.com/yaoyueduzhen/HomOTL-ODDM" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
          </p>
          <p>
            <b>Yuntao Du</b>, Zhiwen Tan, Qian Chen, Yi Zhang, Chongjun Wang.
          </p>
          <p style="color: red;">
            <strong>ECAI 2020 (CCF B)</strong>

          </p>
        </li>
	
</ul>
	

	
	
<h2><font face="Arial"> Honors &amp; Awards </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

    <li>Outstanding Undergraduate Student Award, from NJU, China, May 2023</li>
    <li>Student travel grant, CIKM 2021</li>
    <li> First class scholarship of Yingcai, from NJU, October 2019,2020,2021,2022</li>
    <!-- <li>Financial aid of ICML 2021, July, 2021</li> -->
    <!--   <li>Star of tomorrow, from MSRA, China, September 2020</li> -->
    <li>Outstanding Undergraduate Student Award, from NEU, China, May 2018</li>
    <li>Meritorious Winner, in MCM/ICM 2017, March 2017</li>
    <!-- <li>National Scholarship for Encouragement, from NEU, October 2015,2016,2017</li> -->

</p>
</ul>

<h2><font face="Arial"> Work Experience </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>[05/2020 - 10/2020]  Research Intern, Machine Learning Group, MSRA</li>
</p>
</ul>

<h2><font face="Arial"> Professional Activities </font></h2>
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Journal Reviewer </strong> <br> </font> </p> 
    
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Transactions on Machine Learning Research (TMLR) </p></li>	
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Knowledge-Based Systems </p></li>
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Conference Reviewer </strong> <br> </font> </p> 
   <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        The Conference on Neural Information Processing Systems (NeurIPS) 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        International Conference on Learning Representations (ICLR) 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Computer Vision (ICCV) 2023, 2021 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        European Conference on Computer Vision (ECCV) 2024, 2022 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022, 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        AAAI Conference on Artificial Intelligence (AAAI) 2022, 2023, 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        ACM International Conference on Multimedia (ACM MM) 2021, 2023 </p></li>
</ul>
		

<div id="footer">
	<div id="footer-text"></div>
</div>
	<p></p><center>
        <br>
            ¬© Yuntao Du | Last updated: 15/9/2024
        </center><p></p>

</b></b></b></div><b><b><b>

</b></b></b></body></html>
