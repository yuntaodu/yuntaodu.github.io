<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Yuntao Du, Shandong University"> 
<meta name="description" content="Yuntao Du's home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuntao Du's homepage</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');
<style>
  .left-align {
    text-align: left;
  }
</style>
	
</script>
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1><font face="Arial"> Yuntao Du </font></h1>  <h1><font face="楷体"> 杜云涛 </font></h1>
				</div>

				<h3><font face="Arial"> Associate Researcher </font></h3>
				<p><font face="Arial"> 
					Joint SDU-NTU Centre for Artificial Intelligence Research & School of Software <br>
					<a href="http://www.hku.hk/" target="_blank"> Shandong University</a> <br>
					Jinan, China <br>
					<br>
					Email: <a href="duyuntao@bigai.ai">yuntaodu@sdu.edu.cn</a> <br>
				</font></p>
			</td>
			<td>
				<img src="yuntaodu.jpg" border="0" width="180"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2><font face="Arial"> About </font></h2>
<p class="left-align";>

    Currently, I am  working as an Associate Researcher in the School of Software, at Shandong University. Before that, I was a research scientist at the Beijing Institute for General Artificial Intelligence (BIGAI). I got a Ph.D degree from  Nanjing University in June 2023. I was a member of
    <a href = "http://iip.nju.edu.cn/index.php/%E9%A6%96%E9%A1%B5" target="_blank" style= "color:blue; text-decoration:none;" >IIP Group</a>,
    led by professor
    <a href = "https://cs.nju.edu.cn/58/06/c2639a153606/page.htm" target="_blank" style= "color:blue; text-decoration:none;" >Chongjun Wang</a>. Before that, I received my B.Sc. degree from Northeastern University in June 2018. <br>
    <!-- In September 2018, I was admitted to study for a Ph.D degree at Nanjing University under the supervision of Prof. <a href = "https://cs.nju.edu.cn/58/06/c2639a153606/page.htm" target="_blank" style= "color:blue; text-decoration:none;" >Chongjun Wang</a> without entrance examination, respectively. -->
    <br>
    I am working on multimodal understanding, reasoning, and new knowledge learning. In particular, I'm interested in building models/agents that can generalize well and learn continously in various reasoning and multimodal tasks. Some of my research topic could be found below: 
    <ul>
        <li> <b>Large language model</b>: RAG, Knowledge and reasoning
	      <li> <b>Large multimodal model</b>:  Efficient training and inference,   knowledge editing, model evaluation
        <li> <b>LLM Agent</b>:    Multi-agent system; Agent Applications
        <li> <b>Transfer Learing & Weakly supervised learning </b>:   domain adaptation, test-time adaptation, semi-supervised learning, noisy-label learning 
    </ul>
    
</font></p>

	
<!--<font color="red">Currently, I am working on domain generalization for semantic segmentation and object detection. I am looking for undergraduate or master students to engage in ongoing research papers. Don't hesitate to email me if you are interested.</font> <br><br>-->
	
<h2><font face="Arial"> News </h2>
<font size = "3"></font>
    <ul>
      <li> 2025.05 One paper got accepted by <b>ICML 2025</b></li>
      <li> 2025.03 One paper got accepted by <b>Neural Networks</b></li>
      <li> <p style="color: red;">2025.02  <strong> I have joined Shandong University as an Associate Researcher in the School of Software.  </strong></p>
      </li>
      <li> 2025.01 One paper got accepted by <b>ICLR 2025</b></li>
      <li> 2024.12 One paper got accepted by <b>AAAI 2025</b></li>
      <li> 2024.11 One paper got accepted by <b>Neurocomputing 2024</b></li>
      <li> 2024.09 One paper got accepted by <b>NeurIPS 2024</b></li>
      <li> 2024.08 One paper got accepted by <b>Neural Network</b></li>
      <li> 2024.07 One paper got accepted by <b>ECCV 2024</b></li>
      <!-- <li> 2024.03 One paper got accepted by <b>ICLR 2024 workshop</b></li> -->
      <li> 2024.03 One paper got accepted by <b>CVPR 2024</b></li>
      <!-- <li> 2024.02 Our survey on parameter efficient fine-tuning for vision is on arvix. Here is the <a href="https://github.com/synbol/Awesome-Parameter-Efficient-Transfer-Learning" target="_blank" style= "color:blue; text-decoration:none;">github link</a> </li> -->
      <li> 2023.10 One paper got accepted by <strong>Machine Learning Journal</strong>
      <li> 2023.03 One paper got accepted by <strong>Transactions on Machine Learning Research (TMLR) </strong>
      <!-- <li> 2023.01 One paper got accepted by <strong>SDM 2023 </strong> -->
<!--         <li> 2022.12 One paper got accepted by <strong>AAAI 2023</strong> -->
<!--         <li> 2022.06 One paper got accepted by <strong>ECML-PKDD 2022</strong>
        <li> 2021.12 One paper got accepted by <strong>AAAI 2022</strong> -->
        <!-- <li> 2021.09 I have been awarded a student travel grant of CIKM 2021</li> -->
        <!-- <li> 2021.09 I have been selected as a PC member of AAAI 2022</li> -->
        <!-- <li> 2021.08 Two papers got accepted by <strong> CIKM 2021 </strong></li>
        <li> 2021.05 One paper got accepted by <strong> ICMR 2021 </strong></li>
        <li> 2021.03 One paper got accepted by <strong> IDA journal 2021 </strong></li>
        <li> 2021.01 Four papers got accepted by <strong> DASFAA 2021 </strong></li> -->
      <!--   <li> 2020.06 One paper got accepted by <strong> ECML-PKDD 2020 </strong></li> -->
      </ul>




<h2><font face="Arial"> Preprint </font></h2>
<font size = "3">
<ul>
    <li> 
	   <p>
		   <strong> When Large Multimodal Models Confront Evolving Knowledge: Challenges and Pathways.</strong>  
       <a href="" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
	   </p>
           Kailin Jiang*, <b>Yuntao Du*</b>, Yukai Ding, Yuchen Ren, Ning Jiang, Zhi Gao, Zilong Zheng, Lei Liu, Bin Li, Qing Li.
    </li>
    <li>
    <p>
        <strong>Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey. </strong>  
        <a href="https://arxiv.org/abs/2402.02242" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
    </p>
    <p>
        Yi Xin, Siqi Luo, Haodi Zhou, Junlong Du, Xiaohong Liu, Yue Fan, Qing Li, <b>Yuntao Du*</b>
    </p>
    </li>
</ul>


<h2><font face="Arial"> Selected Publications </font></h2>
<font size = "2"></font>
<p><font face="Arial"><a href="https://scholar.google.com/citations?user=1ogwTXkAAAAJ&hl=zh-CN">[Google Scholar]</a></font></p> 
	
<ul>

  <li>
    <p>
      <strong>	Test-Time Selective Adaptation for Uni-Modal Distribution Shift in Multi-Modal Data. </strong> 
      <a href="" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a> 
    <p>
      MingCai Chen, Baoming Zhang, Zongbo Han, <b>Yuntao Du*</b>, Wenyu Jiang, Yanmeng Wang, Shuai Feng, Bingkun BAO
    </p>
    <p>
      <strong>   <p style="color: blue;">ICML 2025 (Equal Corresponding Author)</p>   </strong>
    </p>
</li>


  <li>
    <p>
      <strong>	MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge. </strong>
      <a href="https://openreview.net/forum?id=v8qABSeeKO&noteId=iGPriZPvEo" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
      <a href="https://mmke-bench-iclr.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
    <p>
      <b>Yuntao Du</b>, Kailin Jiang, Zhi Gao, Chenrui Shi, Zilong Zheng, Siyuan Qi, Qing Li
    </p>
    <p>
     <strong>  <p style="color: blue;">ICLR 2025 </p>  </strong> 
    </p>
</li>

<li>
    <p>
      <strong>Robust Logit Adjustment for Learning with Long-Tailed Noisy Data. </strong> 
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33738" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
    <p>
      MingCai Chen, <b>Yuntao Du</b>, Wenyu Jiang, Baoming Zhang, Shuai Feng, Yi Xin, Chongjun Wang
    </p>
    <p>
      <strong> <p style="color: blue;">AAAI  2025  </p>  </strong>
    </p>
</li>

    <li>
    <p>
      <strong>V-PETL Bench: A Unified Visual Parameter-Efficient Transfer Learning Benchmark. </strong> 
       <a href="https://openreview.net/pdf?id=yS1dUkQFnu" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
       <a href="https://v-petl-bench.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
    <p>
      Yi Xin*, Siqi Luo*, Xuyang Liu*, <b>Yuntao Du*</b>, Haodi Zhou, Xinyu Cheng, Christina Luoluo Lee, Junlong Du, Haozhe Wang, MingCai Chen, Ting Liu, Guimin Hu, Zhongwei Wan, Rongchao Zhang, Aoxue Li, Mingyang Yi, Xiaohong Liu
    </p>
    <p>
      <strong>  <p style="color: blue;">NeurIPS 2024 </p> </strong>  
    </p>

</li>
    <li>
        <p>
          <strong>VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding. </strong> 
          <a href="https://arxiv.org/abs/2403.11481" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
          <a href="https://videoagent.github.io/" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
          <a href="https://mp.weixin.qq.com/s/2gG9AUcTc_yutN8zZUGQKQ" target="_blank" style= "color:blue; text-decoration:none;">[机器之心中文报道]</a>
        <p>
          Yue Fan, Xiaojian Ma, Rujie Wu, <b>Yuntao Du</b>, Jiaqi Li, Zhi Gao, Qing Li
        </p>
        <p>
          <strong> <p style="color: blue;">ECCV 2024 </p> </strong>  
        </p>
    </li>

    <li>
        <p>
          <strong>Multi-source Fully Test-Time Adaptation. </strong> 
          <a href="https://www.sciencedirect.com/science/article/pii/S0893608024005859" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Siqi Luo, Yi Xin, MingCai Chen, Shuai Feng, Mujie Zhang, Chongjun Wang
        </p>
        <p>
          <strong>  <p style="color: blue;">Neural Network 2024 </p> </strong>
        </p>
      </li>
        <li>
          <p>
            <strong> CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update. </strong> 
            <a href="https://arxiv.org/abs/2312.10908" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
            <a href="https://clova-tool.github.io" target="_blank" style= "color:blue; text-decoration:none;">[WebPage]</a>
          <p>
            Zhi Gao, <b>Yuntao Du</b>, Xintong Zhang, Xiaojian Ma, Wenjuan Han, Song-Chun Zhu, Qing Li
          </p>
          <p>
            <strong> <p style="color: blue;">CVPR 2024 </p>  </strong> 
          </p>
        </li>
      <li>
        <p>
          <strong>Generation, augmentation, and alignment: A pseudo-source domain based method for source-free domain adaptation </strong>
          <a href="https://arxiv.org/abs/2109.04015" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Haiyang Yang, Mingcai Chen, Juan Jiang, Hongtao Luo, and Chongjun Wang.
        </p>
        <p>
          <strong> <p style="color: blue;">Machine Learning (MLJ)  2023 </p>  </strong>
        </p>
      </li>
  
      <li>
        <p>
          <strong>DSCR: Dual View based Symmetric Consistency Regularization for Semi-Supervised Domain Adaptation </strong>
          <a href="https://openreview.net/pdf?id=WVwnccBJLz" target="_blank" style= "color:blue; text-decoration:none;">[PDF]</a>
        </p>
        <p>
          <b>Yuntao Du</b>, Juan Jiang, Hongtao Luo, Haiyang Yang, Mingcai Chen, and Chongjun Wang.
        </p>
        <p>
          <strong>  <p style="color: blue;"> Transactions on Machine Learning Research (TMLR) 2023 </p> </strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong>Two Wrongs Don’t Make a Right: Combating Confirmation Bias in Learning with Label Noise</strong>
          [<a href="https://arxiv.org/abs/2112.02960" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
        </p>
        <p>
          Mingcai Chen, Hao Cheng, <b>Yuntao Du </b>, Ming Xu, Wenyu Jiang, Chongjun Wang
        </p>
        <p>
          <strong><p style="color: blue;"> AAAI 2023 </p> </strong>  
        </p>
      </li>
      <li>
        <p> 
          <strong>InCo: Intermediate Prototype Contrast for Unsupervised Domain Adaptation</strong>
          [<a href="https://link.springer.com/chapter/10.1007/978-3-031-26387-3_39" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
        </p>
        <p>
          <b>Yuntao Du*</b>, Hongtao Luo*, Haiyang Yang, Juan Jiang, and Chongjun Wang
        </p>
        <p  style="color: blue;">
           <strong>ECML-PKDD 2022</strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong> Semi-Supervised Learning with Multi-Head Co-Training</strong>
          [<a href="https://arxiv.org/pdf/2107.04795" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/chenmc1996/Multi-Head-Co-Training" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
        <p>
          Mingcai Chen, <b>Yuntao Du </b>, Yi zhang, Shuwei Qian, and Chongjun Wang
        </p>
        <p style="color: blue;">
         <strong> AAAI 2022 </strong>
        </p>
      </li>
  
      <li>
        <p> 
          <strong>AdaRNN: Adaptive Learning and Forecasting of Time Series</strong>
          [<a href="https://arxiv.org/abs/2108.04443" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn" target="_blank" style= "color:blue; text-decoration:none;">Code</a>](<b>引用超290</b>)  
        </p>
        <p>
          <b>Yuntao Du </b>, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu and Chongjun Wang
        </p>
        <p style="color: blue;">
          <strong>CIKM  2021 </strong> 
       </p>
      </li>
  
      <li>
        <p> 
          <strong>Adversarial Separation Network for Cross-Network Node Classification</strong>
          [<a href="https://dl.acm.org/doi/10.1145/3459637.3482228" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
          [<a href="https://github.com/yuntaodu/ASN" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
        <p>
          Xiaowen Zhang *, <b>Yuntao Du *</b>, Rongbiao Xie and Chongjun Wang (*, euqal contribution)
        </p>
        <p style="color: blue;">
          <strong>CIKM 2021 </strong> 
        </p>
      </li>

      <!-- <li>
        <p> 
          <strong>Cross-domain error minimization for unsupervised domain adaptation</strong>
        </p>
        <p>
          <b>Yuntao Du</b>, Yinghao Chen *, Fengli Cui *, Xiaowen Zhang, Chongjun Wang. (*, euqal contribution)
        </p>
        <p>
          International Conference on Database Systems for Advanced Applications (<a href="http://dm.iis.sinica.edu.tw/DASFAA2021/" target="_blank" style= "color:blue; text-decoration:none;"><strong>DASFAA</strong></a>) 2021 [<a href="https://arxiv.org/abs/2106.15057" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] [<a href="https://github.com/yuntaodu/CDEM" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
        </p>
      </li> -->

      <li>
          <p> 
            <strong>Homogeneous Online Transfer Learning with Online Distribution Discrepancy Minimization</strong>
            [<a href="https://arxiv.org/pdf/1912.13226.pdf" target="_blank" style= "color:blue; text-decoration:none;">PDF</a>] 
            [<a href="https://github.com/yaoyueduzhen/HomOTL-ODDM" target="_blank" style= "color:blue; text-decoration:none;">Code</a>] 
          </p>
          <p>
            <b>Yuntao Du</b>, Zhiwen Tan, Qian Chen, Yi Zhang, Chongjun Wang.
          </p>
          <p style="color: blue;">
            <strong>ECAI 2020 </strong>

          </p>
        </li>
	
</ul>
	

	
	
<h2><font face="Arial"> Honors &amp; Awards </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">

    <li>Outstanding Undergraduate Student Award, from NJU, China, May 2023</li>
    <li>Student travel grant, CIKM 2021</li>
    <li> First class scholarship of Yingcai, from NJU, October 2019,2020,2021,2022</li>
    <!-- <li>Financial aid of ICML 2021, July, 2021</li> -->
    <!--   <li>Star of tomorrow, from MSRA, China, September 2020</li> -->
    <li>Outstanding Undergraduate Student Award, from NEU, China, May 2018</li>
    <li>Meritorious Winner, in MCM/ICM 2017, March 2017</li>
    <!-- <li>National Scholarship for Encouragement, from NEU, October 2015,2016,2017</li> -->

</p>
</ul>

<h2><font face="Arial"> Work Experience </h2>
	
<ul style="list-style-type:none">
<p style="line-height: 120%; margin-left: 0px; margin-top: 8pt; margin-bottom: 8pt;"> <font face="Arial" size="3">
<li>[05/2020 - 10/2020]  Research Intern, Machine Learning Group, MSRA</li>
</p>
</ul>

<h2><font face="Arial"> Professional Activities </font></h2>
<ul style="list-style-type:none"> 
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Journal Reviewer </strong> <br> </font> </p> 
    
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Transactions on Machine Learning Research (TMLR) </p></li>	
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        Knowledge-Based Systems </p></li>
	 <li> <p style="margin-left: 0px; line-height: 120%; margin-top: 8px; margin-bottom: 8px;"><font face="Arial" size="3"><meta charset="utf-8">
         <strong> Conference Reviewer </strong> <br> </font> </p> 
   <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        The Thirty-Ninth Conference on Neural Information Processing Systems (NeurIPS) 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        International Conference on Learning Representations (ICLR) 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE International Conference on Computer Vision (ICCV) 2023, 2021 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        European Conference on Computer Vision (ECCV) 2024, 2022 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022, 2023 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        AAAI Conference on Artificial Intelligence (AAAI) 2022, 2023, 2024 </p></li>
    <li> <p style="margin-left: 10px; line-height: 150%; margin-top: -6px; margin-bottom: -6px;">
        ACM International Conference on Multimedia (ACM MM) 2021, 2023 </p></li>
</ul>
		

<div id="footer">
	<div id="footer-text"></div>
</div>
	<p></p><center>
        <br>
            © Yuntao Du | Last updated: 15/9/2024
        </center><p></p>

</b></b></b></div><b><b><b>

</b></b></b></body></html>
